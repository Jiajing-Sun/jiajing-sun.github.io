---
title: "An RKHS-based approach to double-penalized regression in high-dimensional partially linear models"
collection: publications
category: manuscripts
permalink: /publication/2018-01-01-rkhs-regression
excerpt: 'This paper introduces an RKHS-based approach for double-penalized regression in high-dimensional partially linear models.'
date: 2018-01-01
venue: 'Journal of Multivariate Analysis'
paperurl: 'https://doi.org/10.1016/j.jmva.2018.07.013'
bibtexurl: 'https://academicpages.github.io/files/bibtex10.bib'
citation: 'Cui, W., Cheng, H., & Sun, J. (2018). "An RKHS-based approach to double-penalized regression in high-dimensional partially linear models." <i>Journal of Multivariate Analysis</i>, 168, 201-210.'
---
## Abstract

We study simultaneous variable selection and estimation in high-dimensional partially linear models under the assumption that the nonparametric component is from a reproducing kernel Hilbert space (RKHS) and that the vector of regression coefficients for the parametric component is sparse. A double penalty is used to deal with the problem. The estimate of the nonparametric component is subject to a roughness penalty based on the squared semi-norm on the RKHS, and a penalty with oracle properties is used to achieve sparsity in the parametric component. Under regularity conditions, we establish the consistency and rate of convergence of the parametric estimation together with the consistency of variable selection. The proposed estimators of the non-zero coefficients are also shown to have the asymptotic oracle property. Simulations and empirical studies illustrate the performance of the method.

[Link to full paper](https://doi.org/10.1016/j.jmva.2018.07.013)
